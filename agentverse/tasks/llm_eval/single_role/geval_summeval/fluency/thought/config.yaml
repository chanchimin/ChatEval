prompts:
  prompt: &prompt |-
    You will be given one summary written for a news article.

    Your task is to rate the summary on one metric.

    Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.


    Evaluation Criteria:

    Fluency (1-3): the quality of the summary in terms of grammar, spelling, punctuation, word choice, and sentence structure.

    - 1: Poor. The summary has many errors that make it hard to understand or sound unnatural.
    - 2: Fair. The summary has some errors that affect the clarity or smoothness of the text, but the main points are still comprehensible.
    - 3: Good. The summary has few or no errors and is easy to read and follow.


    Example:

    Summary:

    ${generated_text}


    Evaluation Form (scores ONLY):

    - Fluency (1-3):

environment:
  env_type: llm_eval
  max_turns: 1
  rule:
    order:
      type: concurrent
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  -
    agent_type: llm_eval
    name: Annotator
    role_description: |-
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-3.5-turbo"
      llm_type: gpt-3.5-turbo
      temperature: 0
      max_tokens: 256

tools: ~