prompts:
  prompt: &prompt |-
    Imagine you are a human annotator now. You will evaluate the quality of summaries written for a medical report.

    Please follow these steps:

    1. Carefully read the medical report, and be aware of the information it contains.
    2. Read the proposed summary.
    3. Rate the summary on four dimensions: relevance, consistency, fluency, and coherence.

    You should rate on a scale from 1 (worst) to 5 (best).
    Definitions are as follows:

    - Relevance: The rating measures how well the summary captures the key points of the medical report. Consider whether all and only the important aspects are contained in the summary.
    - Consistency: The rating measures whether the facts in the summary are consistent with the facts in the original medical report. Consider whether the summary does reproduce all facts accurately and does not make up untrue information.
    - Fluency: This rating measures the quality of individual sentences, whether they are well-written and grammatically correct. Consider the quality of individual sentences.
    - Coherence: The rating measures the quality of all sentences collectively, to fit together and sound natural. Consider the quality of the summary as a whole.

    The original medical report and the summary are given below:
    Original medical report: ${reference_text}
    Summary: ${generated_text}

    When you give the response, you must use the following format, first give the score of the summary of the above 4 aspects then finally give the reasoning on why you give this score:

    Relevance:
    Consistency:
    Fluency:
    Coherence:
    Thought: (your thought)

name: llm_eval

environment:
  env_type: basic
  max_turns: 1
  rule:
    order:
      type: concurrent
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  -
    agent_type: llm_eval
    name: referee
    role_description:  |-

    memory: 
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-4"
      llm_type: gpt-4
      temperature: 0.3
      max_tokens: 128

tools: ~