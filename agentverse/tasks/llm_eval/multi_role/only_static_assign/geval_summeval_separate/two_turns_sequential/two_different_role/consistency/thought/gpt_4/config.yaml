prompts:
  prompt: &prompt |-
    You will be given a news article. You will then be given one summary written for this article.

    Your task is to rate the summary on one metric.

    Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.


    Evaluation Criteria:

    Consistency (1-5) - the factual alignment between the summary and the summarized source. A factually consistent summary contains only statements that are entailed by the source document. Annotators were also asked to penalize summaries that contained hallucinated facts.

    Evaluation Steps:

    1. Read the news article carefully and identify the main facts and details it presents.
    2. Read the summary and compare it to the article. Check if the summary contains any factual errors that are not supported by the article.
    3. Assign a score for consistency based on the Evaluation Criteria.

    Example:


    Source Text:

    ${source_text}

    Summary:

    ${generated_text}

    Additionally, There will be another few people given the same task like you, and you are required to discuss with each other, you can share the idea on how you think of the summary.

    Here is your discuss history:
    ${chat_history}

    ${role_description}

    Now, What is your opinion, ${agent_name} ?

    ${final_prompt}

environment:
  env_type: llm_eval
  max_turns: 4
  rule:
    order:
      type: sequential
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  -
    agent_type: llm_eval_multi
    name: General Public
    final_prompt_to_use: |-
      Please first provide a comprehensive explanation of your evaluation.
      Then, output one lines indicating the scores for the aspect.

      Remember that you are not required to output the same value as other referees !
      Output with the following format strictly:
      Evaluation evidence: [your explanation here]
      Consistency: [score only]
    role_description: |-
      You are now General Public, one of the referees in this task. You are interested in the story and looking for updates on the investigation. Please think critically by yourself and note that it's your responsibility to choose one of which is the better first.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-4"
      llm_type: gpt-4
      temperature: 0
      max_tokens: 512
  -
    agent_type: llm_eval_multi
    name: Critic
    final_prompt_to_use: |-
      Please first provide a comprehensive explanation of your evaluation.
      Then, output one lines indicating the scores for the aspect.

      Remember that you are not required to output the same value as other referees !
      Output with the following format strictly:
      Evaluation evidence: [your explanation here]
      Consistency: [score only]
    role_description: |-
      You are now Critic, one of the referees in this task. You will check fluent writing, clear sentences, and good wording in summary writing. Your job is to question others judgement to make sure their judgement is well-considered and offer an alternative solution if two responses are at the same level.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-4"
      llm_type: gpt-4
      temperature: 0
      max_tokens: 512

tools: ~